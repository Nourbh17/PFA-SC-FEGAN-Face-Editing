{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Nourbh17/PFA-SC-FEGAN-Face-Editing/blob/main/losses.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n0ob1GKzZ4VF"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.applications.vgg16 import VGG16\n",
        "from tensorflow.keras.models import Model\n",
        "\n",
        "class GeneratorLosses():\n",
        "    # gsn_loss function computes this generator loss. By negating the mean of the discriminator's output for the fake data,\n",
        "    # the generator is encouraged to produce data that the discriminator will classify as real,\n",
        "    # thereby minimizing the Wasserstein distance between the real and fake data distributions.\n",
        "    def gsn_loss(dis_fake):\n",
        "        gen_loss = - tf.reduce_mean(dis_fake)\n",
        "        return gen_loss\n",
        "    def per_pixel_loss(gen_output, ground_truth, mask, alpha):\n",
        "        _, n_h, n_w, n_c = ground_truth.get_shape().as_list()\n",
        "\n",
        "        term_1 = tf.reduce_sum(mask * (gen_output - ground_truth)) / (n_h * n_w * n_c)\n",
        "        term_2 = tf.reduce_sum((1. - mask) * (gen_output - ground_truth)) / (n_h * n_w * n_c)\n",
        "\n",
        "        loss = term_1 + alpha * term_2\n",
        "        return loss\n",
        "\n",
        "    pool_layers = [\"pool1\", \"pool2\", \"pool3\"]\n",
        "    def get_vgg16_layers(layers_names):\n",
        "        vgg = VGG16(include_top=False, input_shape=(512, 512, 3), weights='imagenet')\n",
        "        vgg.trainable = False\n",
        "        outputs = [vgg.get_layer(name).output for name in layers_names]\n",
        "        model = Model(inputs=vgg.input, outputs=outputs)\n",
        "        return model\n",
        "    vgg = get_vgg16_layers(pool_layers)\n",
        "\n",
        "    def perceptual_loss(complete_image, ground_truth, gen_image):\n",
        "        features_ground_truth = vgg(ground_truth)\n",
        "        features_output_image = vgg(complete_image)\n",
        "        features_gen_image = vgg(gen_image)\n",
        "\n",
        "\n",
        "        assert len(features_ground_truth) == 3\n",
        "        assert len(features_output_image) == 3\n",
        "        assert len(features_gen_image) == 3\n",
        "\n",
        "        term_1 = 0.\n",
        "        term_2 = 0.\n",
        "        for i in range(len(features_ground_truth)):\n",
        "            _, n_h, n_w, n_c = features_ground_truth[i].get_shape().as_list()\n",
        "            loss = tf.reduce_sum(features_output_image[i] - features_ground_truth[i]) / (n_h * n_w * n_c)\n",
        "            term_1 += loss\n",
        "            loss2 = tf.reduce_sum(features_gen_image[i] - features_ground_truth[i]) / (n_h * n_w * n_c)\n",
        "            term_2 += loss2\n",
        "        return term_1 + term_2\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "Tp25Zt-4Gd-D"
      }
    }
  ]
}