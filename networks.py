# -*- coding: utf-8 -*-
"""Networks.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1BI4aRTxV9HIKKQUtW_EHpiumI2Ql434v
"""

import tensorflow as tf


class Generator(object):
    def __init__(self, input_size, batch_size):
        self.input_size = input_size
        self.batch_size = batch_size

    def build_gen(self, x, mask, name='generator', reuse=False, training=True):
        cnum = 64
        s_h, s_w = self.input_size, self.input_size
        s_h2, s_w2 = int(self.input_size / 2), int(self.input_size / 2)
        s_h4, s_w4 = int(self.input_size / 4), int(self.input_size / 4)
        s_h8, s_w8 = int(self.input_size / 8), int(self.input_size / 8)
        s_h16, s_w16 = int(self.input_size / 16), int(self.input_size / 16)
        s_h32, s_w32 = int(self.input_size / 32), int(self.input_size / 32)
        s_h64, s_w64 = int(self.input_size / 64), int(self.input_size / 64)
        with tf.variable_scope(name, reuse=reuse):
            # encoder
            x_now = x
            x1, mask1 = self.gate_conv(x, cnum, 7, 2, use_lrn=False, name='gconv1_ds')
            x2, mask2 = self.gate_conv(x1, 2 * cnum, 5, 2, name='gconv2_ds')
            x3, mask3 = self.gate_conv(x2, 4 * cnum, 5, 2, name='gconv3_ds')
            x4, mask4 = self.gate_conv(x3, 8 * cnum, 3, 2, name='gconv4_ds')
            x5, mask5 = self.gate_conv(x4, 8 * cnum, 3, 2, name='gconv5_ds')
            x6, mask6 = self.gate_conv(x5, 8 * cnum, 3, 2, name='gconv6_ds')
            x7, mask7 = self.gate_conv(x6, 8 * cnum, 3, 2, name='gconv7_ds')

            # dilated conv
            x7, _ = self.gate_conv(x7, 8 * cnum, 3, 1, rate=2, name='co_conv1_dlt')
            x7, _ = self.gate_conv(x7, 8 * cnum, 3, 1, rate=4, name='co_conv2_dlt')
            x7, _ = self.gate_conv(x7, 8 * cnum, 3, 1, rate=8, name='co_conv3_dlt')
            x7, _ = self.gate_conv(x7, 8 * cnum, 3, 1, rate=16, name='co_conv4_dlt')

            # decoder
            x8, _ = self.gate_deconv(x7, [self.batch_size, s_h64, s_w64, 8 * cnum], name='deconv1')
            x8 = tf.concat([x6, x8], axis=3)
            x8, mask8 = self.gate_conv(x8, 8 * cnum, 3, 1, name='gconv8')

            x9, _ = self.gate_deconv(x8, [self.batch_size, s_h32, s_w32, 8 * cnum], name='deconv2')
            x9 = tf.concat([x5, x9], axis=3)
            x9, mask9 = self.gate_conv(x9, 8 * cnum, 3, 1, name='gconv9')

            x10, _ = self.gate_deconv(x9, [self.batch_size, s_h16, s_w16, 8 * cnum], name='deconv3')
            x10 = tf.concat([x4, x10], axis=3)
            x10, mask10 = self.gate_conv(x10, 8 * cnum, 3, 1, name='gconv10')

            x11, _ = self.gate_deconv(x10, [self.batch_size, s_h8, s_w8, 4 * cnum], name='deconv4')
            x11 = tf.concat([x3, x11], axis=3)
            x11, mask11 = self.gate_conv(x11, 4 * cnum, 3, 1, name='gconv11')

            x12, _ = self.gate_deconv(x11, [self.batch_size, s_h4, s_w4, 2 * cnum], name='deconv5')
            x12 = tf.concat([x2, x12], axis=3)
            x12, mask12 = self.gate_conv(x12, 2 * cnum, 3, 1, name='gconv12')

            x13, _ = self.gate_deconv(x12, [self.batch_size, s_h2, s_w2, cnum], name='deconv6')
            x13 = tf.concat([x1, x13], axis=3)
            x13, mask13 = self.gate_conv(x13, cnum, 3, 1, name='gconv13')

            x14, _ = self.gate_deconv(x13, [self.batch_size, s_h, s_w, 3], name='deconv7')
            x14 = tf.concat([x_now, x14], axis=3)
            x14, mask14 = self.gate_conv(x14, 3, 3, 1, activation=None, use_lrn=False, name='gconv14')

            output = tf.tanh(x14)

            return output, mask14
    def gate_conv (self,x_in, cnum, ksize, stride=1, rate=1, name='conv',
             padding='SAME', activation='leaky_relu', use_lrn=True,training=True):
        if padding == 'SYMMETRIC' or padding == 'REFELECT':
            p = int(rate*(ksize-1)/2)
            x = tf.pad(x_in, [[0,0], [p, p], [p, p], [0,0]], mode=padding)
            padding = 'VALID'
        x = tf.layers.conv2d(
            x_in, cnum, ksize, stride, dilation_rate=rate,
            activation=None, padding=padding, name=name)
        if use_lrn:
            x = tf.nn.lrn(x, bias=0.00005)
        if activation=='leaky_relu':
            x = tf.nn.leaky_relu(x)

        g = tf.layers.conv2d(
            x_in, cnum, ksize, stride, dilation_rate=rate,
            activation=tf.nn.sigmoid, padding=padding, name=name+'_g')

        x = tf.multiply(x,g)
        return x, g

    def gate_deconv(input_, output_shape, k_h=5, k_w=5, d_h=2, d_w=2, stddev=0.02,
           name="deconv", training=True):
        with tf.variable_scope(name):
            # filter : [height, width, output_channels, in_channels]
            w = tf.get_variable('w', [k_h, k_w, output_shape[-1], input_.get_shape()[-1]],
                      initializer=tf.random_normal_initializer(stddev=stddev))

            deconv = tf.nn.conv2d_transpose(input_, w, output_shape=output_shape,
                        strides=[1, d_h, d_w, 1])

            biases = tf.get_variable('biases1', [output_shape[-1]], initializer=tf.constant_initializer(0.0))
            deconv = tf.reshape(tf.nn.bias_add(deconv, biases), deconv.get_shape())
            deconv = tf.nn.leaky_relu(deconv)

            g = tf.nn.conv2d_transpose(input_, w, output_shape=output_shape,
                        strides=[1, d_h, d_w, 1])
            b = tf.get_variable('biases2', [output_shape[-1]], initializer=tf.constant_initializer(0.0))
            g = tf.reshape(tf.nn.bias_add(g, b), deconv.get_shape())
            g = tf.nn.sigmoid(deconv)

            deconv = tf.multiply(g,deconv)

            return deconv, g

# import tensorflow as tf
# from tensorflow.keras.applications import VGG16

# # Load pre-trained VGG-16 model
# vgg = VGG16(weights='imagenet', include_top=False)

# # Define selected layers for feature extraction
# selected_layers = ['block1_pool', 'block2_pool', 'block3_pool']

# def compute_perceptual_loss(Igen, Icomp, Igt):
#     perceptual_loss = 0.0

#     for layer_name in selected_layers:
#         # Extract feature maps for generated image, completion image, and ground truth image
#         feature_map_gen = vgg.get_layer(layer_name).output
#         feature_map_comp = vgg.get_layer(layer_name).output
#         feature_map_gt = vgg.get_layer(layer_name).output

#         # Compute L1 distances between feature maps of generated image and ground truth image
#         l1_distance_gen = tf.reduce_mean(tf.abs(feature_map_gen - feature_map_gt))
#         l1_distance_comp = tf.reduce_mean(tf.abs(feature_map_comp - feature_map_gt))

#         # Normalize L1 distances by the number of elements in the feature maps
#         num_elements = tf.cast(tf.reduce_prod(tf.shape(feature_map_gt)), dtype=tf.float32)
#         normalized_l1_distance_gen = l1_distance_gen / num_elements
#         normalized_l1_distance_comp = l1_distance_comp / num_elements

#         # Accumulate normalized L1 distances
#         perceptual_loss += normalized_l1_distance_gen + normalized_l1_distance_comp

#     # Average the accumulated normalized L1 distances
#     perceptual_loss /= len(selected_layers)

#     return perceptual_loss

# # Example usage:
# # Assuming Igen, Icomp, and Igt are tensors representing the generated image, completion image, and ground truth image, respectively
# # loss = compute_perceptual_loss(Igen, Icomp, Igt)

def PatchGAN(inp_shape=(256,256,3)):

    model = tf.keras.models.Sequential()

    model.add(tf.keras.layers.InputLayer(input_shape=inp_shape))

    model.add(tf.keras.layers.Conv2D(filters=64, kernel_size=3, strides=2, padding='same', activation='relu'))

    model.add(tf.keras.layers.Conv2D(filters=128, kernel_size=3, strides=2, padding='same', activation='relu'))

    tf.keras.layers.BatchNormalization(),
    model.add(tf.keras.layers.Conv2D(filters=256, kernel_size=3, strides=2, padding='same', activation='relu'))

    tf.keras.layers.BatchNormalization(),
    model.add(tf.keras.layers.ZeroPadding2D())
    model.add(tf.keras.layers.Conv2D(filters=512, kernel_size=3, strides=1, padding='valid', activation='relu'))

    tf.keras.layers.BatchNormalization(),
    model.add(tf.keras.layers.ZeroPadding2D())
    model.add(tf.keras.layers.Conv2D(filters=1, kernel_size=3, strides=1, padding='valid', activation='sigmoid'))

    return model

# def conv2d_layer(inputs, out_channels, kernel_size, stride=1, padding='valid', activation=None, use_bn=False, use_sn=False):
#     x = tf.keras.layers.Conv2D(out_channels, kernel_size, strides=stride, padding=padding)(inputs)
#     if use_bn:
#         x = tf.keras.layers.BatchNormalization()(x)
#     if activation:
#         x = activation(x)
#     if use_sn:
#         x = SpectralNorm(x)
#     return x

class Conv2DLayer(tf.keras.layers.Layer):
    def __init__(self, out_channels, kernel_size, stride=1, padding='valid', activation=None, use_bn=False, use_sn=False):
        super(Conv2DLayer, self).__init__()
        self.out_channels = out_channels
        self.kernel_size = kernel_size
        self.stride = stride
        self.padding = padding
        self.activation = activation
        self.use_bn = use_bn
        self.use_sn = use_sn

    def build(self, input_shape):
        self.conv2d = tf.keras.layers.Conv2D(self.out_channels, self.kernel_size, strides=self.stride, padding=self.padding)
        if self.use_bn:
            self.batch_norm = tf.keras.layers.BatchNormalization()
        if self.use_sn:
            self.spectral_norm = SpectralNormalization()

    def call(self, inputs):
        x = self.conv2d(inputs)
        if self.use_bn:
            x = self.batch_norm(x)
        if self.activation:
            x = self.activation(x)
        if self.use_sn:
            x = self.spectral_norm(x)
        return x

def patch_discriminator(img, mask, opt):
    x = tf.concat([img, mask], axis=-1)
    x = conv2d_layer(x, 64, 3, 1, padding='same', activation=tf.nn.leaky_relu, use_sn=True)
    x = conv2d_layer(x, 128, 3, 2, padding='same', activation=tf.nn.leaky_relu, use_sn=True, use_bn=True)
    x = conv2d_layer(x, 256, 3, 2, padding='same', activation=tf.nn.leaky_relu, use_sn=True, use_bn=True)
    x = conv2d_layer(x, 512, 3, 2, padding='same', activation=tf.nn.leaky_relu, use_sn=True, use_bn=True)
    x = conv2d_layer(x, 512, 3, 2, padding='same', activation=tf.nn.leaky_relu, use_sn=True, use_bn=True)
    x = conv2d_layer(x, 1, 3, 2, padding='same', activation=None, use_sn=True)
    return x

class SpectralNorm(tf.keras.layers.Wrapper):
  def __init__(self, layer, iteration=1, name="weight", **kwargs):
    super(SpectralNorm, self).__init__(layer, **kwargs)
    self.iteration = iteration
    self.name = name

  def build(self, input_shape):
    if not hasattr(self.layer, self.name):
      raise ValueError(f"Layer {self.layer.name} does not have attribute {self.name}")
    w = getattr(self.layer, self.name)
    self.w_bar = self.add_weight(
        shape=w.shape,
        name=f"{self.name}_bar",
        initializer=tf.keras.initializers.TruncatedNormal(stddev=1.0),
        trainable=True
    )
    self.u = self.add_weight(
        shape=(w.shape[0], 1),
        name=f"{self.name}_u",
        initializer=tf.random.normal_initializer(mean=0.0, stddev=1.0),
        trainable=False
    )
    self.v = self.add_weight(
        shape=(1, w.shape[1]),
        name=f"{self.name}_v",
        initializer=tf.random.normal_initializer(mean=0.0, stddev=1.0),
        trainable=False
    )
    super(SpectralNorm, self).build(input_shape)

  def call(self, inputs, training=None):
    if training:
      self._update_u_v(inputs)
    sigma = tf.tensordot(self.u, tf.matmul(self.w_bar, self.v), axes=([0], [1]))
    self.layer.setattr(self.name, self.w_bar / sigma)
    return self.layer(inputs)

  def _update_u_v(self, inputs):
    w_reshaped = tf.reshape(self.w_bar, (-1, self.w_bar.shape[1]))
    for _ in range(self.iteration):
      v = tf.nn.l2_normalize(tf.matmul(tf.transpose(w_reshaped), self.u), axis=0)
      self.u.assign(tf.nn.l2_normalize(tf.matmul(w_reshaped, v), axis=1))



