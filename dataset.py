# -*- coding: utf-8 -*-
"""Dataset.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1eR7eJFq2wpcd0ITXuXesL3N5pnKo2j-p
"""

from google.colab import drive
drive.mount('/content/drive')

import tensorflow as tf
import numpy as np

import zipfile
import os

# Path to the zip file
zip_file_path = '/content/drive/MyDrive/CelebAMask-HQ.zip'

# Directory where you want to extract the contents
extracted_dir = '/content/drive/MyDrive/celebahq'

# Create the target directory if it doesn't exist
os.makedirs(extracted_dir, exist_ok=True)

# Extract the contents of the zip file
with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:
    zip_ref.extractall(extracted_dir)

# List the contents of the extracted directory
extracted_files = os.listdir(extracted_dir)
print(f"Contents of {extracted_dir}: {extracted_files}")

data_dir= '/content/drive/MyDrive/celebahq/CelebAMask-HQ/CelebA-HQ-img'
data = tf.keras.utils.image_dataset_from_directory(data_dir,labels=None,label_mode=None,shuffle=True,image_size=(512,512),batch_size=None)

# train_split = 0.03334

# # Create training dataset
# train_ds = tf.keras.utils.image_dataset_from_directory(
#     data_dir,
#     labels=None,label_mode=None,
#     validation_split=train_split,
#     subset="training",
#     seed=123,  # Set random seed for reproducibility
#     image_size=(512, 512),
#     batch_size=32  # Adjust batch size as needed
# )

# # Create test dataset
# test_ds = tf.keras.utils.image_dataset_from_directory(
#     data_dir,
#     labels=None,label_mode=None,
#     validation_split=train_split,
#     subset="validation",  # Use "validation" to get the remaining split
#     seed=123,  # Keep the same seed for consistency
#     image_size=(512, 512),
#     batch_size=32
# )

# # Print information about the datasets
# print("Training dataset size:", train_ds.cardinality())
# print("Test dataset size:", test_ds.cardinality().numpy())

test_dataset = data.take(1000)
train_dataset = data.skip(1000)

len(test_dataset)

# for images in data:
#     # Access the shape of the first image in the batch
#     image_shape = images[0].shape
#     print("Image shape:", image_shape)
#     break  # Exit after checking one batch

def free_form_mask(IntputImage,inputSize, maxDraw, maxLine, maxAngle, maxLength,max_width):
  mask=np.zeros((inputSize,inputSize),np.float32)
  HairMask=GFCHair(IntputImage)
  numLine=np.random.randint(maxDraw)
  for i in range(numLine):
      startX = np.random.randint(inputSize)
      startY = np.random.randint(inputSize)

      mask=subFFmask(inputSize, maxAngle, maxLength,max_width,startX,startY,mask)
      e1,e2= give_eye_position(IntputImage)
      mask=subFFmask(inputSize, maxAngle, maxLength,max_width,e1[0],e1[1],mask)
      mask=subFFmask(inputSize, maxAngle, maxLength,max_width,e2[0],e2[1],mask)



  mask = mask +HairMask
  return mask.reshape((1, ) + mask.shape).astype(np.float32)

def subFFmask(inputSize, maxAngle, maxLength,max_width,startX,startY,mask):
  startAngle = np.random.randint(360)
  numV =np.random.randint(maxLine)
  for j in range(numV):
         angleP = np.random.randint(-maxAngle,maxAngle)
         if (j % 2)==0:
           angle = startAngle+angleP
         else:
           angle = startAngle+angleP+180

         length = np.random.range(maxLength)
         brush_w = 5 + np.random.randint(max_width)
         end_x = (startX + length * np.sin(angle)).astype(np.int32)
         end_y = (startY + length * np.cos(angle)).astype(np.int32)
         cv2.line(mask, (startX, startX), (end_y, end_x), 1.0, brush_w)
         startX, startY = end_x, end_y
  return mask.reshape((1, ) + mask.shape).astype(np.float32)

import mediapipe as mp
import cv2
def give_eye_position(img):

 # Load the MediaPipe FaceMesh solution
 mp_face_mesh = mp.solutions.face_mesh
 face_mesh = mp_face_mesh.FaceMesh()



 # Process the image with FaceMesh
 results = face_mesh.process((cv2.cvtColor(img, cv2.COLOR_BGR2RGB)))

 # Extract the eye centers
 if results.multi_face_landmarks:
    for face_landmarks in results.multi_face_landmarks:
        # Define the landmark indices for the left and right eye
        left_eye_landmark_indices = [33, 133, 143, 153, 159, 145]
        right_eye_landmark_indices = [362, 263, 373, 380, 374, 386]

        # Initialize the eye center coordinates
        left_eye = [0, 0]
        right_eye = [0, 0]
        for i in range(2):
         e1=np.random.choice(left_eye_landmark_indices)
         e2=np.random.choice(right_eye_landmark_indices)
         landmark = face_landmarks.landmark[e1]
         x = int(landmark.x * img.shape[1])
         y = int(landmark.y * img.shape[0])
         left_eye[0] += x
         left_eye[1] += y
         landmark = face_landmarks.landmark[e2]
         xx = int(landmark.x * img.shape[1])
         yy = int(landmark.y * img.shape[0])
         right_eye[0] += x
         right_eye[1] += y



    # Calculate the average eye center coordinates
    left_eye[0] //= 2
    left_eye[1] //= 2
    right_eye[0] //= 2
    right_eye[1] //= 2
    return  (left_eye, right_eye)